{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline for Monday, March 8**\n",
    "\n",
    "More Dictionaries\n",
    "\n",
    "You will be able to:\n",
    " - Select the appropriate data structure for a situation\n",
    " - Use the pop() and get() methods with default values\n",
    " - \"Bucket\" data using lists inside a dictionary\n",
    " - Simulate a table with a list of dictionaries\n",
    "\n",
    "Useful methods\n",
    " - .get()\n",
    " - .pop()\n",
    " - .keys()\n",
    " - .values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n",
      "st\n",
      "th\n",
      "{1: 'st', 2: 'nd', 3: 'rd'}\n",
      "nd\n",
      "{1: 'st', 3: 'rd'}\n"
     ]
    }
   ],
   "source": [
    "#Task: Produce suffixes for numbers (note that \"th\" is the default and is not included!)\n",
    "suffix = {1:\"st\", 2:'nd', 3:\"rd\"}\n",
    "#suffix.pop(5) #KeyError\n",
    "#suffix[4] #KeyError\n",
    "print(suffix.get(4,\"th\")) #get(key, default_value)\n",
    "print(suffix.get(1,\"th\"))\n",
    "print(suffix.pop(0,\"th\")) #pop(key, default_value) <-- will remove the matching key-value pair if it exists,\n",
    "print(suffix)             #    and otherwise will JUST return the default value\n",
    "print(suffix.pop(2,\"th\"))\n",
    "print(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#Defaultdict is a separate type of dictionary\n",
    "# Restriction: Have to specify ONE type of value for it to hold\n",
    "# Benefit: If a key is not present, defaultdict assumes that key has the default value for that value type\n",
    "\n",
    "x = defaultdict(int)\n",
    "print(x[\"hi\"]) #Even though there is no key \"hi\", it has the default int value of 0 when we lookup it\n",
    "\n",
    "#Use case: The tornado years_counts function we wrote on Friday can be rewritten more elegantly using defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Structures**\n",
    "\n",
    "A _data structure_ is a collection of *values*, the *relationships* among them, and the functions or *operations* that can be applied to the data.\n",
    "\n",
    "| | values | relationships | operations |\n",
    "| :- | :- | :- | :- |\n",
    "| list | anything | ordered (indexes 0, 1, ...) | len(), indexing, pop(), slicing, interation (for), ... |\n",
    "| set | anything (BUT no repeats) | no ordering | in, == |\n",
    "| dict | key-value pairs (almost anything) | no ordering, BUT lookup values by their keys | keys(), values(), len(), lookup, insertion, deletion |\n",
    "| ... | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing the right data structure**\n",
    "\n",
    "\n",
    " - grocery list (can of tomatoes, 2 peppers, milk)\n",
    "  - Probably a list? Maybe a set? (How do we want to handle the possibility of repeat items?)\n",
    " - player scores in a game (Alexi has 5, Meena has 8, Andy has 20)\n",
    "  - dict (Notice the natural key-value pairs with name and score)\n",
    " - tornado counts by year\n",
    "  - dict (Key-value pairs again! with year and the count)\n",
    " - tornado names used\n",
    "  - set (If there have been 5 tornados \"bob\", I still only care that bob is IN my used_names set)\n",
    " - tornado entries by year\n",
    "  - dict where each value is list of lists (dict maps year to a list of tornado entries - each tornado entry is a list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bucketing (also known as \"binning\")**\n",
    "\n",
    "What is it?\n",
    " - Take data (initially in a big list)\n",
    " - Send each data entry to a list inside a value in a dict\n",
    " - Distribute by some category within the data itself\n",
    "\n",
    "Why bucket data?\n",
    " - A way to organize our data, without losing information in the process\n",
    "\n",
    "How is this different from what we did on Friday?\n",
    " - The \"without losing information in the process\" part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#copied from https://automatetheboringstuff.com/2e/chapter16\n",
    "def process_csv(filename):\n",
    "    exampleFile = open(filename, encoding=\"utf-8\")\n",
    "    exampleReader = csv.reader(exampleFile)\n",
    "    exampleData = list(exampleReader)\n",
    "    exampleFile.close()\n",
    "    return exampleData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last time...**\n",
    "\n",
    "We used tornados.csv to make a dictionary that counted the tornados in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#See tornados.csv\n",
    "tornado_data = process_csv(\"tornados.csv\")\n",
    "tornado_data\n",
    "\n",
    "years_counts = {}\n",
    "for t in tornado_data[1:]:\n",
    "    #t is each tornado entry in turn\n",
    "    #use years_counts to keep count of tornados in each year\n",
    "    year = t[0]\n",
    "    if year in years_counts: #tests if year is a valid key\n",
    "        years_counts[year] += 1\n",
    "    else:\n",
    "        years_counts[year] = 1\n",
    "    \n",
    "print(list(years_counts.keys())) #list of all the keys in the dictionary\n",
    "print(list(years_counts.values())) #list of all the values in the dictionary\n",
    "#DO NOT RELY ON ORDERING\n",
    "\n",
    "for key in years_counts:\n",
    "    if key.startswith(\"2\"):\n",
    "        print(key,years_counts[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Today: Bucket tornado data**\n",
    "\n",
    "Write a function that buckets the data by a given column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'id', 'location', 'speed']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'site B': [['2006', 'QPIQPWDP', 'site B', '175'],\n",
       "  ['1996', 'MMMHKDDK', 'site B', '290'],\n",
       "  ['2016', 'QSCAPJBU', 'site B', '290'],\n",
       "  ['2002', 'EYIVKEWL', 'site B', '199'],\n",
       "  ['1997', 'NSCJTEAU', 'site B', '222'],\n",
       "  ['2011', 'AUJLPQWN', 'site B', '243'],\n",
       "  ['2010', 'SZRUOPIH', 'site B', '201'],\n",
       "  ['2008', 'FUBXASWR', 'site B', '255'],\n",
       "  ['2003', 'VFIBJORY', 'site B', '240'],\n",
       "  ['2001', 'VTBWHKRH', 'site B', '271'],\n",
       "  ['2009', 'VLEHBLKH', 'site B', '141'],\n",
       "  ['2010', 'CETAQQXF', 'site B', '202'],\n",
       "  ['2017', 'YWHUCOUS', 'site B', '194'],\n",
       "  ['2015', 'YDPQWWGV', 'site B', '130'],\n",
       "  ['1995', 'EMCQGXEG', 'site B', '155']],\n",
       " 'site C': [['2014', 'KKGOICYZ', 'site C', '122'],\n",
       "  ['1996', 'JRHLYGLS', 'site C', '238'],\n",
       "  ['2001', 'QRYMLENE', 'site C', '174'],\n",
       "  ['2002', 'IZXLGNRJ', 'site C', '269'],\n",
       "  ['2005', 'CWGFYTZZ', 'site C', '109'],\n",
       "  ['2017', 'LIBFCJBB', 'site C', '181'],\n",
       "  ['2017', 'CNMZERWF', 'site C', '218'],\n",
       "  ['2003', 'NQSHEURP', 'site C', '155'],\n",
       "  ['2004', 'KRMJSZGY', 'site C', '137'],\n",
       "  ['2008', 'TVEGOJAM', 'site C', '272'],\n",
       "  ['2005', 'EXXPOMSB', 'site C', '236'],\n",
       "  ['2001', 'ZSPSCPBT', 'site C', '259'],\n",
       "  ['2014', 'CCCCYZBY', 'site C', '264'],\n",
       "  ['2014', 'EWLAXYVH', 'site C', '153'],\n",
       "  ['1996', 'TOXIMTKE', 'site C', '290'],\n",
       "  ['2002', 'QZKYNJFZ', 'site C', '250'],\n",
       "  ['1995', 'KYUONPMV', 'site C', '187']],\n",
       " 'site A': [['2015', 'ZDMHZTXL', 'site A', '147'],\n",
       "  ['2005', 'FEBIJZIF', 'site A', '198'],\n",
       "  ['1995', 'JDUTRHFQ', 'site A', '281'],\n",
       "  ['2005', 'AWLDIUCW', 'site A', '173'],\n",
       "  ['1995', 'RCAOONFD', 'site A', '198'],\n",
       "  ['1995', 'XCBWVUIF', 'site A', '234'],\n",
       "  ['2016', 'JQPYBXEI', 'site A', '139'],\n",
       "  ['2016', 'BJDRTWIW', 'site A', '286'],\n",
       "  ['1996', 'WIMYUNGE', 'site A', '187'],\n",
       "  ['1996', 'LJJJYSDQ', 'site A', '209'],\n",
       "  ['2002', 'EONEPHOZ', 'site A', '213'],\n",
       "  ['2013', 'GTKGJLKN', 'site A', '220'],\n",
       "  ['2017', 'YNBKDYTA', 'site A', '179'],\n",
       "  ['1998', 'DIBERSNP', 'site A', '240'],\n",
       "  ['2016', 'KOBWSFXW', 'site A', '186'],\n",
       "  ['2007', 'DBEESDMM', 'site A', '159'],\n",
       "  ['2002', 'VKANHNPC', 'site A', '175'],\n",
       "  ['2007', 'DSSUCXOI', 'site A', '265'],\n",
       "  ['2014', 'BPNKITVS', 'site A', '296'],\n",
       "  ['2009', 'JRKTSFOU', 'site A', '112'],\n",
       "  ['2013', 'RQYVUUGR', 'site A', '259'],\n",
       "  ['2008', 'PHSPFJVR', 'site A', '257'],\n",
       "  ['2009', 'ZUCZYBOC', 'site A', '258'],\n",
       "  ['2004', 'DWIDLQEZ', 'site A', '287'],\n",
       "  ['1997', 'MEYDGPRX', 'site A', '272'],\n",
       "  ['2011', 'TLSAVUXI', 'site A', '230']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tornado_data = process_csv(\"tornados.csv\")\n",
    "headers = tornado_data[0]\n",
    "tornado_data = tornado_data[1:]\n",
    "print(headers)\n",
    "\n",
    "def bucket_tornados(tornado_data,headers,col):\n",
    "    \"\"\"Bucket the tornado data by the given column and return the resulting dict\"\"\"\n",
    "    d = {}\n",
    "    col_index = headers.index(col)\n",
    "    for tornado in tornado_data:\n",
    "        col_value = tornado[col_index]\n",
    "        if col_value not in d:\n",
    "            d[col_value] = [tornado] #Creates a new list for the new bucket, with one element (tornado) in that list\n",
    "        else:\n",
    "            d[col_value].append(tornado)\n",
    "    return d\n",
    "\n",
    "bucket_tornados(tornado_data, headers, \"location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A different way of organizing data**\n",
    "\n",
    "Process a CSV file into a _list_ of _dictionaries_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': '2006', 'id': 'QPIQPWDP', 'location': 'site B', 'speed': '175'},\n",
       " {'year': '1996', 'id': 'MMMHKDDK', 'location': 'site B', 'speed': '290'},\n",
       " {'year': '2016', 'id': 'QSCAPJBU', 'location': 'site B', 'speed': '290'},\n",
       " {'year': '2014', 'id': 'KKGOICYZ', 'location': 'site C', 'speed': '122'},\n",
       " {'year': '2015', 'id': 'ZDMHZTXL', 'location': 'site A', 'speed': '147'},\n",
       " {'year': '2005', 'id': 'FEBIJZIF', 'location': 'site A', 'speed': '198'},\n",
       " {'year': '2002', 'id': 'EYIVKEWL', 'location': 'site B', 'speed': '199'},\n",
       " {'year': '1995', 'id': 'JDUTRHFQ', 'location': 'site A', 'speed': '281'},\n",
       " {'year': '1997', 'id': 'NSCJTEAU', 'location': 'site B', 'speed': '222'},\n",
       " {'year': '2005', 'id': 'AWLDIUCW', 'location': 'site A', 'speed': '173'},\n",
       " {'year': '1996', 'id': 'JRHLYGLS', 'location': 'site C', 'speed': '238'},\n",
       " {'year': '2001', 'id': 'QRYMLENE', 'location': 'site C', 'speed': '174'},\n",
       " {'year': '1995', 'id': 'RCAOONFD', 'location': 'site A', 'speed': '198'},\n",
       " {'year': '2002', 'id': 'IZXLGNRJ', 'location': 'site C', 'speed': '269'},\n",
       " {'year': '2011', 'id': 'AUJLPQWN', 'location': 'site B', 'speed': '243'},\n",
       " {'year': '1995', 'id': 'XCBWVUIF', 'location': 'site A', 'speed': '234'},\n",
       " {'year': '2010', 'id': 'SZRUOPIH', 'location': 'site B', 'speed': '201'},\n",
       " {'year': '2016', 'id': 'JQPYBXEI', 'location': 'site A', 'speed': '139'},\n",
       " {'year': '2016', 'id': 'BJDRTWIW', 'location': 'site A', 'speed': '286'},\n",
       " {'year': '2005', 'id': 'CWGFYTZZ', 'location': 'site C', 'speed': '109'},\n",
       " {'year': '2017', 'id': 'LIBFCJBB', 'location': 'site C', 'speed': '181'},\n",
       " {'year': '1996', 'id': 'WIMYUNGE', 'location': 'site A', 'speed': '187'},\n",
       " {'year': '2017', 'id': 'CNMZERWF', 'location': 'site C', 'speed': '218'},\n",
       " {'year': '2008', 'id': 'FUBXASWR', 'location': 'site B', 'speed': '255'},\n",
       " {'year': '1996', 'id': 'LJJJYSDQ', 'location': 'site A', 'speed': '209'},\n",
       " {'year': '2002', 'id': 'EONEPHOZ', 'location': 'site A', 'speed': '213'},\n",
       " {'year': '2003', 'id': 'NQSHEURP', 'location': 'site C', 'speed': '155'},\n",
       " {'year': '2003', 'id': 'VFIBJORY', 'location': 'site B', 'speed': '240'},\n",
       " {'year': '2004', 'id': 'KRMJSZGY', 'location': 'site C', 'speed': '137'},\n",
       " {'year': '2001', 'id': 'VTBWHKRH', 'location': 'site B', 'speed': '271'},\n",
       " {'year': '2008', 'id': 'TVEGOJAM', 'location': 'site C', 'speed': '272'},\n",
       " {'year': '2005', 'id': 'EXXPOMSB', 'location': 'site C', 'speed': '236'},\n",
       " {'year': '2013', 'id': 'GTKGJLKN', 'location': 'site A', 'speed': '220'},\n",
       " {'year': '2009', 'id': 'VLEHBLKH', 'location': 'site B', 'speed': '141'},\n",
       " {'year': '2017', 'id': 'YNBKDYTA', 'location': 'site A', 'speed': '179'},\n",
       " {'year': '1998', 'id': 'DIBERSNP', 'location': 'site A', 'speed': '240'},\n",
       " {'year': '2001', 'id': 'ZSPSCPBT', 'location': 'site C', 'speed': '259'},\n",
       " {'year': '2016', 'id': 'KOBWSFXW', 'location': 'site A', 'speed': '186'},\n",
       " {'year': '2010', 'id': 'CETAQQXF', 'location': 'site B', 'speed': '202'},\n",
       " {'year': '2007', 'id': 'DBEESDMM', 'location': 'site A', 'speed': '159'},\n",
       " {'year': '2017', 'id': 'YWHUCOUS', 'location': 'site B', 'speed': '194'},\n",
       " {'year': '2014', 'id': 'CCCCYZBY', 'location': 'site C', 'speed': '264'},\n",
       " {'year': '2002', 'id': 'VKANHNPC', 'location': 'site A', 'speed': '175'},\n",
       " {'year': '2007', 'id': 'DSSUCXOI', 'location': 'site A', 'speed': '265'},\n",
       " {'year': '2014', 'id': 'EWLAXYVH', 'location': 'site C', 'speed': '153'},\n",
       " {'year': '2014', 'id': 'BPNKITVS', 'location': 'site A', 'speed': '296'},\n",
       " {'year': '2015', 'id': 'YDPQWWGV', 'location': 'site B', 'speed': '130'},\n",
       " {'year': '2009', 'id': 'JRKTSFOU', 'location': 'site A', 'speed': '112'},\n",
       " {'year': '1996', 'id': 'TOXIMTKE', 'location': 'site C', 'speed': '290'},\n",
       " {'year': '2002', 'id': 'QZKYNJFZ', 'location': 'site C', 'speed': '250'},\n",
       " {'year': '1995', 'id': 'KYUONPMV', 'location': 'site C', 'speed': '187'},\n",
       " {'year': '2013', 'id': 'RQYVUUGR', 'location': 'site A', 'speed': '259'},\n",
       " {'year': '2008', 'id': 'PHSPFJVR', 'location': 'site A', 'speed': '257'},\n",
       " {'year': '2009', 'id': 'ZUCZYBOC', 'location': 'site A', 'speed': '258'},\n",
       " {'year': '2004', 'id': 'DWIDLQEZ', 'location': 'site A', 'speed': '287'},\n",
       " {'year': '1995', 'id': 'EMCQGXEG', 'location': 'site B', 'speed': '155'},\n",
       " {'year': '1997', 'id': 'MEYDGPRX', 'location': 'site A', 'speed': '272'},\n",
       " {'year': '2011', 'id': 'TLSAVUXI', 'location': 'site A', 'speed': '230'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_list = process_csv(\"tornados.csv\")\n",
    "header = data_as_list[0]\n",
    "data_as_list = data_as_list[1:]\n",
    "data_as_list_of_dicts = []\n",
    "for tornado in data_as_list:\n",
    "    new_dict = {}\n",
    "    data_as_list_of_dicts.append(new_dict)\n",
    "    for index in range(len(header)):\n",
    "        new_dict[header[index]] = tornado[index]\n",
    "data_as_list_of_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge Problem**\n",
    "\n",
    "Bucketing can be used to help sort a list. Write a function that takes a list of 3-digit numbers. It works by\n",
    " 1. Bucketing by the 1s digit.\n",
    " 2. \"Flattening\" the buckets into a single list (but now the list is \"sorted\" by 1s digit)\n",
    " 3. Bucketing by the 10s digit.\n",
    " 4. Flattening again\n",
    " 5. Bucketing by the 100s digit.\n",
    " 6. Flattening one last time\n",
    "See if you can explain why this approach sorts the list. How does its speed compare to using the built-in list sort() method? (Remember `from time import time` to help you measure speed.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
